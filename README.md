# WiDS 5.0 â€“ End-to-End Machine Learning Project  
## PlantVillage Disease Classification

**Name:** Sugandh Kumar  
**Roll Number:** 24B0357  
**Program:** WiDS 5.0 (Winter in Data Science)  
**Project Type:** End-to-End Machine Learning / Deep Learning  

---

## ğŸ“Œ Project Overview

This repository contains my complete submission for **WiDS 5.0 End-to-End Machine Learning**, where I worked on the **PlantVillage leaf disease classification dataset**.

The objective of this project was to build a **full ML/DL pipeline**, starting from raw image data and ending with trained and evaluated models, while understanding the challenges involved in real-world image classification tasks.

---

## ğŸ¯ Problem Statement

Given an image of a plant leaf, the goal is to **classify the disease category correctly**.

Key challenges include:
- High number of classes
- Visual similarity between different diseases
- Variations in lighting, texture, and leaf shape
- Risk of overfitting due to complex models

---

## ğŸ“‚ Dataset

- **Dataset:** PlantVillage
- **Type:** Image dataset
- **Classes:** Multiple plantâ€“disease combinations
- **Input:** RGB leaf images
- **Output:** Disease class label

---

## ğŸ§  Project Workflow

The project was completed in a **step-by-step end-to-end manner**, as outlined below:

---

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)

- Explored dataset structure and class distribution
- Visualized sample images from different classes
- Identified class imbalance and inter-class similarity
- Understood why plant disease classification is a challenging task

ğŸ“„ Notebook: `01_eda.ipynb`

---

### 2ï¸âƒ£ Data Preprocessing

- Image resizing and normalization
- Trainâ€“validationâ€“test split with stratification
- Conversion of labels into numerical format
- Efficient data loading for model training

ğŸ“„ Notebook: `02_preprocessing.ipynb`

---

### 3ï¸âƒ£ Baseline Model (Classical ML / Shallow Model)

- Built a **simple baseline model** to set a performance benchmark
- Used flattened image features
- Observed **underfitting and limited generalization**
- Achieved baseline accuracy of approximately **0.67**

ğŸ“„ Notebook: `03_baseline_model.ipynb`

---

### 4ï¸âƒ£ Convolutional Neural Network (CNN)

- Designed a custom CNN architecture
- Trained model using image batches
- Observed:
  - Faster learning
  - Better feature extraction
  - Signs of overfitting after multiple epochs

ğŸ“„ Notebook: `04_simple_cnn.ipynb`

---

### 5ï¸âƒ£ Transfer Learning

- Used a **pretrained CNN model**
- Froze initial layers and fine-tuned later layers
- Achieved significantly better generalization
- Evaluated using:
  - Accuracy
  - Confusion Matrix
  - Validation performance

ğŸ“„ Notebook: `05_transfer_learning.ipynb`

---

### 6ï¸âƒ£ Model Evaluation

- Compared baseline, CNN, and transfer learning models
- Analyzed training vs validation accuracy
- Used confusion matrices to understand misclassifications
- Identified class-level performance issues

---

## ğŸ“Š Results Summary

| Model Type            | Accuracy |
|----------------------|----------|
| Baseline Model       | ~0.67    |
| Simple CNN           | Improved |
| Transfer Learning    | Best     |

> Transfer learning performed the best due to pretrained feature extraction and better generalization.

---

## ğŸ“ Learnings & Observations

All key insights, challenges, mistakes, and takeaways are documented in detail here:

ğŸ“„ **[`learnings.md`](learnings.md)**

This includes:
- Why EDA is critical
- Overfitting vs underfitting insights
- Why CNNs outperform classical ML for images
- Importance of validation accuracy
- Real-world ML challenges

---

## ğŸ› ï¸ Tools & Technologies Used

- Python
- NumPy, Pandas
- Matplotlib, Seaborn
- Scikit-learn
- TensorFlow / Keras
- Jupyter Notebook

---

## ğŸš€ Conclusion

This project helped me gain hands-on experience with:
- End-to-end ML pipelines
- Image-based classification
- CNNs and transfer learning
- Model evaluation and interpretation

Overall, WiDS 5.0 strengthened my understanding of **practical machine learning beyond theory**.

---

## ğŸ“Œ Repository Structure

```text
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_baseline_model.ipynb
â”‚   â”œâ”€â”€ 03_cnn.ipynb
â”œâ”€â”€ learnings.md
â”œâ”€â”€ README.md
